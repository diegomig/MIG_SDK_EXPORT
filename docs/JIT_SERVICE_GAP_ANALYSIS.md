# An√°lisis de Brechas: Servicio JIT seg√∫n Propuesta de Grant

**Fecha**: 18 de Enero, 2026  
**Referencia**: `grants/arbitrum/Core_Proposal/PROJECT_PROPOSAL.md`  
**Estado Actual**: Basado en `benchmarks/flight_recorder_20260118_014659.jsonl`

---

## üéØ Objetivos del Servicio JIT (Seg√∫n Propuesta)

### **Milestone 1 Targets**:
1. ‚úÖ **Cache hit rate**: ‚â•80% (actualmente: 50%)
2. ‚úÖ **JIT state fetch latency**: ‚â§10ms (local node), ‚â§100ms (remote RPC)
3. ‚úÖ **RPC calls per block**: ‚â§30 (actualmente: 20 calls en benchmark)
4. ‚úÖ **End-to-end latency**: ‚â§200ms (discovery ‚Üí graph update)

---

## üìä Estado Actual vs Objetivos

| M√©trica | Objetivo | Actual | Gap | Estado |
|---------|----------|--------|-----|--------|
| **Cache hit rate** | ‚â•80% | 50% | -30% | ‚ö†Ô∏è **FALTA 30%** |
| **JIT latency (local)** | ‚â§10ms | N/A | N/A | ‚è≥ **NO MEDIDO** |
| **JIT latency (remote)** | ‚â§100ms | ~547ms | +447ms | ‚ùå **FALTA OPTIMIZACI√ìN** |
| **RPC calls/block** | ‚â§30 | 20 | ‚úÖ | ‚úÖ **CUMPLIDO** |
| **End-to-end latency** | ‚â§200ms | ~6,300ms | +6,100ms | ‚ùå **FALTA OPTIMIZACI√ìN** |

---

## üîç An√°lisis Detallado de Brechas

### **1. Cache Hit Rate: 50% ‚Üí 80%** ‚ö†Ô∏è

**Gap**: -30 puntos porcentuales

**Causas Identificadas**:
1. ‚ö†Ô∏è **Hot Pool Manager no poblado**: 0 pools en Hot Pool Manager
2. ‚ö†Ô∏è **TTL no diferenciado**: No hay TTL diferenciado para touched/untouched pools
3. ‚ö†Ô∏è **Cache invalidation agresiva**: Puede estar invalidando cache innecesariamente
4. ‚ö†Ô∏è **Fuzzy block matching**: Puede no estar implementado (5-block tolerance)

**Lo que falta implementar** (seg√∫n propuesta):

1. **Merkle Tree-Based Cache Invalidation** ‚ùå
   - Estado actual: Cache invalidation basada en bloques
   - Falta: State hash calculation (sqrt_price_x96, liquidity, tick para V3; reserves para V2)
   - Falta: Cache invalidation solo cuando cambia el state hash (no block-based)

2. **TTL Differentiation Strategy** ‚ùå
   - Estado actual: TTL uniforme (probablemente)
   - Falta: 30s TTL para touched pools (recientes Swap/Mint/Burn events)
   - Falta: 5min TTL para untouched pools
   - Falta: Adaptive TTL basado en pool weight (mayor weight = TTL m√°s corto)

3. **Fuzzy Block Matching** ‚ùå
   - Estado actual: No implementado
   - Falta: 5-block tolerance para cache hits
   - Falta: Batch optimization (priorizar touched pools, batch untouched pools)

4. **Hot Pool Manager Integration** ‚ö†Ô∏è
   - Estado actual: Hot Pool Manager existe pero no se actualiza (0 pools)
   - Falta: Poblar Hot Pool Manager con top pools
   - Falta: Usar Hot Pool Manager para mejorar cache hit rate

---

### **2. JIT State Fetch Latency: ~547ms ‚Üí ‚â§100ms** ‚ùå

**Gap**: +447ms (4.5x m√°s lento que objetivo)

**Causas Identificadas**:
1. ‚ùå **No hay local node integration**: Solo usa RPC remoto (Alchemy)
2. ‚ùå **Multicall batching sub√≥ptimo**: Puede no estar batching eficientemente
3. ‚ùå **Cache no optimizado**: Cache hit rate bajo (50%) significa m√°s RPC calls

**Lo que falta implementar** (seg√∫n propuesta):

1. **Local Node Integration** ‚ùå
   - Estado actual: Solo RPC remoto
   - Falta: Auto-detection de local Reth/Geth nodes
   - Falta: Priority routing (local node ‚Üí primary RPC ‚Üí failover RPCs)
   - Falta: Connection pooling para local node con keep-alive connections
   - Impacto esperado: <10ms con local node (vs ~547ms actual)

2. **Multicall Batching Optimization** ‚ö†Ô∏è
   - Estado actual: Multicall existe pero puede no estar optimizado
   - Falta: Batch size optimization (hasta 200 calls por batch seg√∫n propuesta)
   - Falta: Priorizaci√≥n de touched pools sobre untouched pools

3. **Cache Optimization** ‚ö†Ô∏è
   - Estado actual: Cache hit rate 50%
   - Falta: Mejorar cache hit rate a ‚â•80% (ver secci√≥n 1)
   - Impacto: Menos RPC calls = menor latencia promedio

---

### **3. End-to-End Latency: ~6,300ms ‚Üí ‚â§200ms** ‚ùå

**Gap**: +6,100ms (31.5x m√°s lento que objetivo)

**Desglose Actual**:
- Discovery cycle: ~2,317ms
- Graph update: ~4,029ms
- **Total**: ~6,346ms

**Objetivo**: ‚â§200ms total

**Causas Identificadas**:
1. ‚ùå **Graph update muy lento**: 4.0s para 78 pools (deber√≠a ser <200ms total)
2. ‚ùå **Discovery cycle lento**: 2.3s por ciclo (puede optimizarse)
3. ‚ùå **RPC calls secuenciales**: Puede haber paralelizaci√≥n insuficiente
4. ‚ùå **Price fetching lento**: Hist√≥rico indica que price fetching es 60% del tiempo de graph update

**Lo que falta implementar** (seg√∫n propuesta):

1. **Parallel Price Fetching** ‚ùå
   - Estado actual: Price fetching probablemente secuencial
   - Falta: Parallel price fetching (reducci√≥n esperada: 40% seg√∫n propuesta)
   - Impacto: Graph update de 4.0s ‚Üí ~2.4s (si price fetching es 60% del tiempo)

2. **Batch Database Updates** ‚ö†Ô∏è
   - Estado actual: Puede haber updates individuales
   - Falta: Batch database updates (reducci√≥n esperada: 50% overhead seg√∫n propuesta)

3. **Cache Optimization** ‚ö†Ô∏è
   - Estado actual: Cache hit rate 50%
   - Falta: Mejorar cache hit rate a ‚â•80%
   - Impacto: Menos RPC calls = menor latencia

4. **Local Node Integration** ‚ùå
   - Estado actual: Solo RPC remoto
   - Falta: Local node integration
   - Impacto: RPC calls de ~547ms ‚Üí <10ms (con local node)

---

### **4. RPC Calls per Block: ‚â§30** ‚úÖ

**Estado**: ‚úÖ **CUMPLIDO**
- Actual: 20 calls en benchmark
- Objetivo: ‚â§30 calls
- **Gap**: 0 (ya cumplido)

**Nota**: Este objetivo ya se cumple, pero puede mejorarse a√∫n m√°s con cache optimization.

---

## üöß Componentes Faltantes (Seg√∫n Propuesta)

### **Milestone 1 - Cache Optimization & State Synchronization**

#### **1. Merkle Tree-Based Cache Invalidation** ‚ùå

**Estado**: No implementado

**Falta**:
- `src/cache/state_cache.rs`: Merkle-tree based state cache
- State hash calculation para V2 (reserves) y V3 (sqrt_price_x96, liquidity, tick)
- Cache invalidation solo cuando cambia el state hash (no block-based)
- Unit tests: Cache invalidation logic (property-based tests)

**Archivos a crear/modificar**:
- `src/cache/state_cache.rs` (nuevo)
- `src/jit_state_fetcher.rs` (modificar para usar state hash)
- `src/adapters/` (modificar para calcular state hash)

---

#### **2. TTL Differentiation Strategy** ‚ùå

**Estado**: No implementado

**Falta**:
- TTL diferenciado: 30s para touched pools, 5min para untouched pools
- Adaptive TTL basado en pool weight
- Integraci√≥n con event tracking (Swap/Mint/Burn events)

**Archivos a crear/modificar**:
- `src/hot_pool_manager.rs` (modificar para TTL diferenciado)
- `src/cache/` (nuevo m√≥dulo para TTL management)

---

#### **3. Fuzzy Block Matching** ‚ùå

**Estado**: No implementado

**Falta**:
- 5-block tolerance para cache hits
- Batch optimization (priorizar touched pools)
- L√≥gica de fuzzy matching en JIT state fetcher

**Archivos a crear/modificar**:
- `src/jit_state_fetcher.rs` (modificar para fuzzy block matching)

---

#### **4. Local Node Integration** ‚ùå

**Estado**: No implementado

**Falta**:
- Auto-detection de local Reth/Geth nodes
- Priority routing (local node ‚Üí primary RPC ‚Üí failover)
- Connection pooling para local node
- Configuration: `settings.toml` local node URL option

**Archivos a crear/modificar**:
- `src/rpc_pool.rs` (modificar para local node detection y prioritization)
- `src/settings.rs` (agregar configuraci√≥n de local node)
- Integration tests: Local node fallback scenarios

---

#### **5. Multicall Batching Optimization** ‚ö†Ô∏è

**Estado**: Parcialmente implementado

**Falta**:
- Optimizar batch size (hasta 200 calls por batch seg√∫n propuesta)
- Priorizaci√≥n de touched pools sobre untouched pools
- Batch optimization en JIT state fetcher

**Archivos a crear/modificar**:
- `src/multicall.rs` (optimizar batch size)
- `src/jit_state_fetcher.rs` (integrar batch optimization)

---

#### **6. Parallel Price Fetching** ‚ùå

**Estado**: No implementado

**Falta**:
- Parallel price fetching (reducci√≥n esperada: 40%)
- Integraci√≥n con PriceFeed para parallel fetching

**Archivos a crear/modificar**:
- `src/price_feeds.rs` (modificar para parallel fetching)
- `src/graph_service.rs` (modificar para usar parallel price fetching)

---

#### **7. Batch Database Updates** ‚ö†Ô∏è

**Estado**: Parcialmente implementado

**Falta**:
- Optimizar batch size para database updates
- Reducir overhead de database writes (reducci√≥n esperada: 50%)

**Archivos a crear/modificar**:
- `src/database.rs` (optimizar batch updates)
- `src/graph_service.rs` (usar batch updates)

---

## üìã Checklist de Implementaci√≥n

### **Prioridad P0 (Cr√≠tico para Milestone 1)**:

- [ ] **Merkle Tree-Based Cache Invalidation**
  - [ ] Crear `src/cache/state_cache.rs`
  - [ ] Implementar state hash calculation (V2 y V3)
  - [ ] Modificar cache invalidation para usar state hash
  - [ ] Unit tests (property-based tests)

- [ ] **TTL Differentiation Strategy**
  - [ ] Implementar TTL diferenciado (30s touched, 5min untouched)
  - [ ] Adaptive TTL basado en pool weight
  - [ ] Integraci√≥n con event tracking

- [ ] **Fuzzy Block Matching**
  - [ ] Implementar 5-block tolerance
  - [ ] Batch optimization (priorizar touched pools)
  - [ ] Integrar en JIT state fetcher

- [ ] **Local Node Integration**
  - [ ] Auto-detection de local nodes
  - [ ] Priority routing
  - [ ] Connection pooling
  - [ ] Configuration y tests

### **Prioridad P1 (Importante para Performance)**:

- [ ] **Multicall Batching Optimization**
  - [ ] Optimizar batch size (hasta 200 calls)
  - [ ] Priorizaci√≥n de touched pools

- [ ] **Parallel Price Fetching**
  - [ ] Implementar parallel fetching
  - [ ] Integrar en graph service

- [ ] **Batch Database Updates**
  - [ ] Optimizar batch size
  - [ ] Reducir overhead

### **Prioridad P2 (Mejoras Adicionales)**:

- [ ] **Hot Pool Manager Population**
  - [ ] Poblar Hot Pool Manager con top pools
  - [ ] Integrar con cache para mejorar hit rate

- [ ] **Benchmarking y Validaci√≥n**
  - [ ] Ejecutar benchmarks con optimizaciones
  - [ ] Validar que se cumplen objetivos (‚â•80% cache hit rate, ‚â§100ms latency, ‚â§200ms end-to-end)

---

## üéØ Plan de Acci√≥n Recomendado

### **Fase 1: Cache Optimization (2-3 semanas)**
1. Implementar Merkle Tree-Based Cache Invalidation
2. Implementar TTL Differentiation Strategy
3. Implementar Fuzzy Block Matching
4. Validar cache hit rate ‚â•80%

### **Fase 2: Local Node Integration (1-2 semanas)**
1. Implementar auto-detection de local nodes
2. Implementar priority routing
3. Implementar connection pooling
4. Validar JIT latency ‚â§10ms (local node)

### **Fase 3: Performance Optimization (1-2 semanas)**
1. Optimizar multicall batching
2. Implementar parallel price fetching
3. Optimizar batch database updates
4. Validar end-to-end latency ‚â§200ms

### **Fase 4: Integration & Testing (1 semana)**
1. Integrar todas las optimizaciones
2. Ejecutar benchmarks completos (10,000 blocks)
3. Validar todos los objetivos de Milestone 1
4. Documentar resultados

---

## üìä M√©tricas Esperadas Post-Implementaci√≥n

### **Con Todas las Optimizaciones**:

| M√©trica | Actual | Objetivo | Esperado Post-Optimizaci√≥n |
|---------|--------|----------|----------------------------|
| **Cache hit rate** | 50% | ‚â•80% | **‚â•80%** |
| **JIT latency (local)** | N/A | ‚â§10ms | **<10ms** |
| **JIT latency (remote)** | ~547ms | ‚â§100ms | **<100ms** |
| **RPC calls/block** | 20 | ‚â§30 | **<20** (mejorado) |
| **End-to-end latency** | ~6,300ms | ‚â§200ms | **<200ms** |

---

## ‚úÖ Conclusi√≥n

**Estado General**: El servicio JIT actual est√° **parcialmente implementado** pero **falta optimizaci√≥n cr√≠tica** para alcanzar los objetivos de Milestone 1.

**Componentes Cr√≠ticos Faltantes**:
1. ‚ùå Merkle Tree-Based Cache Invalidation
2. ‚ùå TTL Differentiation Strategy
3. ‚ùå Fuzzy Block Matching
4. ‚ùå Local Node Integration
5. ‚ö†Ô∏è Parallel Price Fetching
6. ‚ö†Ô∏è Batch Database Updates Optimization

**Tiempo Estimado**: 5-8 semanas para implementar todas las optimizaciones y alcanzar los objetivos de Milestone 1.

**Pr√≥ximo Paso**: Comenzar con Fase 1 (Cache Optimization) que es la base para mejorar cache hit rate y reducir RPC calls.
